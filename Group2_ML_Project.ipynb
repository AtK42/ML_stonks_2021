{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group 2: Dekker, Hauser, Tassone, Vogel\n",
    "## buy/hodl/sell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### packages\n",
    "import os\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "import math\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.impute import KNNImputer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### reading data\n",
    "#AH\n",
    "df14 = pd.read_csv(r'C:\\Users\\Aaron\\Documents\\Studium UZH\\Bachelor\\6. Semester\\_Machine Learning\\project\\raw data\\2014_Financial_Data.csv')\n",
    "df15 = pd.read_csv(r'C:\\Users\\Aaron\\Documents\\Studium UZH\\Bachelor\\6. Semester\\_Machine Learning\\project\\raw data\\2015_Financial_Data.csv')\n",
    "df16 = pd.read_csv(r'C:\\Users\\Aaron\\Documents\\Studium UZH\\Bachelor\\6. Semester\\_Machine Learning\\project\\raw data\\2016_Financial_Data.csv')\n",
    "df17 = pd.read_csv(r'C:\\Users\\Aaron\\Documents\\Studium UZH\\Bachelor\\6. Semester\\_Machine Learning\\project\\raw data\\2017_Financial_Data.csv')\n",
    "df18 = pd.read_csv(r'C:\\Users\\Aaron\\Documents\\Studium UZH\\Bachelor\\6. Semester\\_Machine Learning\\project\\raw data\\2018_Financial_Data.csv')\n",
    "\n",
    "\n",
    "df_sp500 = pd.read_csv(r'C:\\Users\\Aaron\\Documents\\Studium UZH\\Bachelor\\6. Semester\\_Machine Learning\\project\\raw data\\sp-500-historical-annual-returns.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### df manipulation\n",
    "df_sp500 = df_sp500[86:91]\n",
    "\n",
    "#add column with year\n",
    "df14['year'] = 2014\n",
    "df15['year'] = 2015\n",
    "df16['year'] = 2016\n",
    "df17['year'] = 2017\n",
    "df18['year'] = 2018\n",
    "\n",
    "#add column for recom\n",
    "df14['recommendation'] = 0\n",
    "df15['recommendation'] = 0\n",
    "df16['recommendation'] = 0\n",
    "df17['recommendation'] = 0\n",
    "df18['recommendation'] = 0\n",
    "\n",
    "#rename 'Price Var' col\n",
    "df14.rename(columns={\"2015 PRICE VAR [%]\": \"PRICE_VAR\"},inplace=True)\n",
    "df15.rename(columns={\"2016 PRICE VAR [%]\": \"PRICE_VAR\"},inplace=True)\n",
    "df16.rename(columns={\"2017 PRICE VAR [%]\": \"PRICE_VAR\"},inplace=True)\n",
    "df17.rename(columns={\"2018 PRICE VAR [%]\": \"PRICE_VAR\"},inplace=True)\n",
    "df18.rename(columns={\"2019 PRICE VAR [%]\": \"PRICE_VAR\"},inplace=True)\n",
    "\n",
    "#dropping name column\n",
    "df14 = df14.drop(df14.columns[0], axis=1)\n",
    "df15 = df15.drop(df15.columns[0], axis=1)\n",
    "df16 = df16.drop(df16.columns[0], axis=1)\n",
    "df17 = df17.drop(df17.columns[0], axis=1)\n",
    "df18 = df18.drop(df18.columns[0], axis=1)\n",
    "\n",
    "#df_all = pd.concat([df14, df15, df16, df17, df18], ignore_index=True) #for after imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Revenue', 'Revenue Growth', 'Cost of Revenue', 'Gross Profit',\n",
       "       'R&D Expenses', 'SG&A Expense', 'Operating Expenses',\n",
       "       'Operating Income', 'Interest Expense', 'Earnings before Tax',\n",
       "       ...\n",
       "       'Asset Growth', 'Book Value per Share Growth', 'Debt Growth',\n",
       "       'R&D Expense Growth', 'SG&A Expenses Growth', 'Sector', 'PRICE_VAR',\n",
       "       'Class', 'year', 'recommendation'],\n",
       "      dtype='object', length=226)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3808 entries, 0 to 3807\n",
      "Columns: 226 entries, Revenue to recommendation\n",
      "dtypes: float64(222), int64(3), object(1)\n",
      "memory usage: 6.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       1\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "3803    1\n",
       "3804    0\n",
       "3805    0\n",
       "3806    1\n",
       "3807    0\n",
       "Name: Class, Length: 3808, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Revenue Growth</th>\n",
       "      <th>Cost of Revenue</th>\n",
       "      <th>Gross Profit</th>\n",
       "      <th>R&amp;D Expenses</th>\n",
       "      <th>SG&amp;A Expense</th>\n",
       "      <th>Operating Expenses</th>\n",
       "      <th>Operating Income</th>\n",
       "      <th>Interest Expense</th>\n",
       "      <th>Earnings before Tax</th>\n",
       "      <th>...</th>\n",
       "      <th>Inventory Growth</th>\n",
       "      <th>Asset Growth</th>\n",
       "      <th>Book Value per Share Growth</th>\n",
       "      <th>Debt Growth</th>\n",
       "      <th>R&amp;D Expense Growth</th>\n",
       "      <th>SG&amp;A Expenses Growth</th>\n",
       "      <th>PRICE_VAR</th>\n",
       "      <th>Class</th>\n",
       "      <th>year</th>\n",
       "      <th>recommendation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.764000e+03</td>\n",
       "      <td>3572.000000</td>\n",
       "      <td>3.734000e+03</td>\n",
       "      <td>3.756000e+03</td>\n",
       "      <td>3.672000e+03</td>\n",
       "      <td>3.749000e+03</td>\n",
       "      <td>3.745000e+03</td>\n",
       "      <td>3.753000e+03</td>\n",
       "      <td>3.745000e+03</td>\n",
       "      <td>3.728000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>3518.000000</td>\n",
       "      <td>3518.000000</td>\n",
       "      <td>3439.000000</td>\n",
       "      <td>3506.000000</td>\n",
       "      <td>3561.000000</td>\n",
       "      <td>3565.000000</td>\n",
       "      <td>3.808000e+03</td>\n",
       "      <td>3808.000000</td>\n",
       "      <td>3808.0</td>\n",
       "      <td>3808.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.879050e+09</td>\n",
       "      <td>12.954244</td>\n",
       "      <td>3.700973e+09</td>\n",
       "      <td>2.188214e+09</td>\n",
       "      <td>9.401830e+07</td>\n",
       "      <td>9.307406e+08</td>\n",
       "      <td>1.438144e+09</td>\n",
       "      <td>6.748248e+08</td>\n",
       "      <td>1.002018e+08</td>\n",
       "      <td>5.725866e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164692</td>\n",
       "      <td>2.279999</td>\n",
       "      <td>0.813931</td>\n",
       "      <td>1.361780</td>\n",
       "      <td>0.596529</td>\n",
       "      <td>0.382284</td>\n",
       "      <td>9.751560e+02</td>\n",
       "      <td>0.429097</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.901741e+10</td>\n",
       "      <td>705.605473</td>\n",
       "      <td>3.040688e+10</td>\n",
       "      <td>1.159028e+10</td>\n",
       "      <td>6.408912e+08</td>\n",
       "      <td>4.820928e+09</td>\n",
       "      <td>7.305171e+09</td>\n",
       "      <td>3.786291e+09</td>\n",
       "      <td>6.991091e+08</td>\n",
       "      <td>2.793740e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>2.195115</td>\n",
       "      <td>92.428920</td>\n",
       "      <td>25.630214</td>\n",
       "      <td>18.734301</td>\n",
       "      <td>25.894049</td>\n",
       "      <td>4.696975</td>\n",
       "      <td>4.098461e+04</td>\n",
       "      <td>0.495012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-6.276160e+08</td>\n",
       "      <td>-1.773200</td>\n",
       "      <td>-5.455740e+08</td>\n",
       "      <td>-1.105000e+09</td>\n",
       "      <td>-1.500000e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.088448e+09</td>\n",
       "      <td>-6.786000e+09</td>\n",
       "      <td>-2.250000e+08</td>\n",
       "      <td>-8.878000e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.979600</td>\n",
       "      <td>-230.000000</td>\n",
       "      <td>-1.051000</td>\n",
       "      <td>-1.043700</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.003972e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.788880e+07</td>\n",
       "      <td>-0.002350</td>\n",
       "      <td>3.135714e+06</td>\n",
       "      <td>3.092900e+07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.548900e+07</td>\n",
       "      <td>3.106600e+07</td>\n",
       "      <td>-1.308000e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-3.732902e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.015400</td>\n",
       "      <td>-0.084550</td>\n",
       "      <td>-0.048200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.003900</td>\n",
       "      <td>-2.857143e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.349010e+08</td>\n",
       "      <td>0.061850</td>\n",
       "      <td>1.414420e+08</td>\n",
       "      <td>1.908760e+08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.381800e+07</td>\n",
       "      <td>1.386610e+08</td>\n",
       "      <td>4.104400e+07</td>\n",
       "      <td>2.563000e+06</td>\n",
       "      <td>2.842700e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062200</td>\n",
       "      <td>0.037100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068800</td>\n",
       "      <td>-5.281842e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.393625e+09</td>\n",
       "      <td>0.188875</td>\n",
       "      <td>1.199844e+09</td>\n",
       "      <td>8.922534e+08</td>\n",
       "      <td>9.911000e+06</td>\n",
       "      <td>3.510000e+08</td>\n",
       "      <td>5.885100e+08</td>\n",
       "      <td>2.712980e+08</td>\n",
       "      <td>4.300000e+07</td>\n",
       "      <td>2.193835e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063850</td>\n",
       "      <td>0.217100</td>\n",
       "      <td>0.141900</td>\n",
       "      <td>0.210300</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>0.220500</td>\n",
       "      <td>1.331484e+01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.824698e+12</td>\n",
       "      <td>42138.663900</td>\n",
       "      <td>1.537249e+12</td>\n",
       "      <td>4.621600e+11</td>\n",
       "      <td>1.153700e+10</td>\n",
       "      <td>1.856830e+11</td>\n",
       "      <td>3.056050e+11</td>\n",
       "      <td>1.565540e+11</td>\n",
       "      <td>3.152300e+10</td>\n",
       "      <td>8.720500e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>76.625000</td>\n",
       "      <td>5468.426400</td>\n",
       "      <td>1360.125000</td>\n",
       "      <td>729.576600</td>\n",
       "      <td>1542.611000</td>\n",
       "      <td>225.690000</td>\n",
       "      <td>2.418601e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 225 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Revenue  Revenue Growth  Cost of Revenue  Gross Profit  \\\n",
       "count  3.764000e+03     3572.000000     3.734000e+03  3.756000e+03   \n",
       "mean   5.879050e+09       12.954244     3.700973e+09  2.188214e+09   \n",
       "std    3.901741e+10      705.605473     3.040688e+10  1.159028e+10   \n",
       "min   -6.276160e+08       -1.773200    -5.455740e+08 -1.105000e+09   \n",
       "25%    5.788880e+07       -0.002350     3.135714e+06  3.092900e+07   \n",
       "50%    4.349010e+08        0.061850     1.414420e+08  1.908760e+08   \n",
       "75%    2.393625e+09        0.188875     1.199844e+09  8.922534e+08   \n",
       "max    1.824698e+12    42138.663900     1.537249e+12  4.621600e+11   \n",
       "\n",
       "       R&D Expenses  SG&A Expense  Operating Expenses  Operating Income  \\\n",
       "count  3.672000e+03  3.749000e+03        3.745000e+03      3.753000e+03   \n",
       "mean   9.401830e+07  9.307406e+08        1.438144e+09      6.748248e+08   \n",
       "std    6.408912e+08  4.820928e+09        7.305171e+09      3.786291e+09   \n",
       "min   -1.500000e+05  0.000000e+00       -1.088448e+09     -6.786000e+09   \n",
       "25%    0.000000e+00  1.548900e+07        3.106600e+07     -1.308000e+06   \n",
       "50%    0.000000e+00  7.381800e+07        1.386610e+08      4.104400e+07   \n",
       "75%    9.911000e+06  3.510000e+08        5.885100e+08      2.712980e+08   \n",
       "max    1.153700e+10  1.856830e+11        3.056050e+11      1.565540e+11   \n",
       "\n",
       "       Interest Expense  Earnings before Tax  ...  Inventory Growth  \\\n",
       "count      3.745000e+03         3.728000e+03  ...       3518.000000   \n",
       "mean       1.002018e+08         5.725866e+08  ...          0.164692   \n",
       "std        6.991091e+08         2.793740e+09  ...          2.195115   \n",
       "min       -2.250000e+08        -8.878000e+09  ...         -1.000000   \n",
       "25%        0.000000e+00        -3.732902e+06  ...          0.000000   \n",
       "50%        2.563000e+06         2.842700e+07  ...          0.000000   \n",
       "75%        4.300000e+07         2.193835e+08  ...          0.063850   \n",
       "max        3.152300e+10         8.720500e+10  ...         76.625000   \n",
       "\n",
       "       Asset Growth  Book Value per Share Growth  Debt Growth  \\\n",
       "count   3518.000000                  3439.000000  3506.000000   \n",
       "mean       2.279999                     0.813931     1.361780   \n",
       "std       92.428920                    25.630214    18.734301   \n",
       "min       -0.979600                  -230.000000    -1.051000   \n",
       "25%       -0.015400                    -0.084550    -0.048200   \n",
       "50%        0.062200                     0.037100     0.000000   \n",
       "75%        0.217100                     0.141900     0.210300   \n",
       "max     5468.426400                  1360.125000   729.576600   \n",
       "\n",
       "       R&D Expense Growth  SG&A Expenses Growth     PRICE_VAR        Class  \\\n",
       "count         3561.000000           3565.000000  3.808000e+03  3808.000000   \n",
       "mean             0.596529              0.382284  9.751560e+02     0.429097   \n",
       "std             25.894049              4.696975  4.098461e+04     0.495012   \n",
       "min             -1.043700             -1.000000 -1.003972e+02     0.000000   \n",
       "25%              0.000000             -0.003900 -2.857143e+01     0.000000   \n",
       "50%              0.000000              0.068800 -5.281842e+00     0.000000   \n",
       "75%              0.004700              0.220500  1.331484e+01     1.000000   \n",
       "max           1542.611000            225.690000  2.418601e+06     1.000000   \n",
       "\n",
       "         year  recommendation  \n",
       "count  3808.0          3808.0  \n",
       "mean   2014.0             0.0  \n",
       "std       0.0             0.0  \n",
       "min    2014.0             0.0  \n",
       "25%    2014.0             0.0  \n",
       "50%    2014.0             0.0  \n",
       "75%    2014.0             0.0  \n",
       "max    2014.0             0.0  \n",
       "\n",
       "[8 rows x 225 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 (3808, 226)\n",
      "15 (4120, 226)\n",
      "16 (4797, 226)\n",
      "17 (4960, 226)\n",
      "18 (4392, 226)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "101103"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "114348"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "212549"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "226269"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "97298"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### some minor EDA\n",
    "df14.columns\n",
    "df14.info() #we have mostly floats, but also 3 integer variables and 1 object variable (-> see 'One-Hot-Encoding' or 'LabelEncoding')\n",
    "df14['Class']\n",
    "df14.describe()\n",
    "\n",
    "#dimensions for each data set\n",
    "year = 14\n",
    "for el in [df14, df15, df16, df17, df18]:\n",
    "    print(year, el.shape)\n",
    "    year += 1\n",
    "\n",
    "#some boxplots\n",
    "#plt.boxplot(df14['PRICE_VAR'])\n",
    "\n",
    "#plt.figure()\n",
    "#df_bp_log = log(df14['Revenue'])#log scale for better visualization\n",
    "#df_bp_log['Sector'] = df14['Sector']\n",
    "#sns.catplot(x=\"Revenue\", y=\"Sector\", kind=\"box\", data=df_bp_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### check missing values\n",
    "df14.isnull().sum().sum()\n",
    "df15.isnull().sum().sum()\n",
    "df16.isnull().sum().sum()\n",
    "df17.isnull().sum().sum()\n",
    "df18.isnull().sum().sum()\n",
    "#df_all.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['operatingCycle',\n",
       " 'cashConversionCycle',\n",
       " 'Net Debt',\n",
       " 'Other Assets',\n",
       " 'priceEarningsToGrowthRatio',\n",
       " 'enterpriseValueMultiple',\n",
       " 'ebtperEBIT',\n",
       " 'niperEBT',\n",
       " 'effectiveTaxRate',\n",
       " 'nIperEBT',\n",
       " 'eBTperEBIT',\n",
       " 'shortTermCoverageRatios',\n",
       " 'dividendPayoutRatio',\n",
       " 'Net Debt to EBITDA',\n",
       " '10Y Revenue Growth (per Share)',\n",
       " '5Y Revenue Growth (per Share)',\n",
       " '10Y Operating CF Growth (per Share)',\n",
       " '5Y Operating CF Growth (per Share)',\n",
       " '10Y Net Income Growth (per Share)',\n",
       " '5Y Net Income Growth (per Share)',\n",
       " '10Y Shareholders Equity Growth (per Share)',\n",
       " '5Y Shareholders Equity Growth (per Share)',\n",
       " '10Y Dividend per Share Growth (per Share)',\n",
       " 'Total non-current assets',\n",
       " 'Total non-current liabilities',\n",
       " 'priceBookValueRatio',\n",
       " 'priceToBookRatio',\n",
       " 'priceCashFlowRatio',\n",
       " 'returnOnAssets',\n",
       " 'returnOnCapitalEmployed',\n",
       " 'payablesTurnover',\n",
       " 'cashFlowToDebtRatio',\n",
       " 'freeCashFlowOperatingCashFlowRatio',\n",
       " 'cashFlowCoverageRatios',\n",
       " 'Enterprise Value',\n",
       " 'PB ratio',\n",
       " 'PTB ratio',\n",
       " 'EV to Sales',\n",
       " 'Enterprise Value over EBITDA',\n",
       " 'EV to Operating cash flow',\n",
       " 'EV to Free cash flow',\n",
       " 'Current ratio',\n",
       " 'Graham Number',\n",
       " 'ROIC',\n",
       " 'Return on Tangible Assets',\n",
       " 'Working Capital',\n",
       " 'Payables Turnover',\n",
       " '3Y Revenue Growth (per Share)',\n",
       " '3Y Operating CF Growth (per Share)',\n",
       " '3Y Net Income Growth (per Share)',\n",
       " '3Y Shareholders Equity Growth (per Share)',\n",
       " '5Y Dividend per Share Growth (per Share)']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### further exploration regarding NAs\n",
    "#function to give back the colnames of cols with more than a certain number (here 1200) of NAs\n",
    "def name_gettr(data, treshold = 1200):\n",
    "    res = {}\n",
    "    for el in data[:1]:\n",
    "        if data[el].isnull().sum() > treshold:\n",
    "            res[el] = data[el].isnull().sum()\n",
    "    return res\n",
    "\n",
    "#apply function defined above\n",
    "df14_outl = name_gettr(df14)\n",
    "df15_outl = name_gettr(df15)\n",
    "df16_outl = name_gettr(df16)\n",
    "df17_outl = name_gettr(df17)\n",
    "df18_outl = name_gettr(df18)\n",
    "\n",
    "\n",
    "#create a list with dictionaries in order to run another function on them \n",
    "df_all_outl = [df14_outl, df15_outl, df16_outl, df17_outl, df18_outl]\n",
    "\n",
    "#function which creates a list with all unique variables that have more than a certain number of NAs for at least one of the years of interest\n",
    "def unique_outl(data):\n",
    "    res = []\n",
    "    for el in data:\n",
    "        for e in el.keys():\n",
    "            if not e in res:\n",
    "                res.append(e)\n",
    "    return(res)\n",
    "\n",
    "#apply function and count number of variables to be retired from df\n",
    "unique_outl(df_all_outl)\n",
    "len(unique_outl(df_all_outl)) #52 (out of 225, i.e. ~23%) variables\n",
    "\n",
    "\n",
    "#further ideas if time allows it:\n",
    "    #graph showing percentages of values missing (see https://www.kaggle.com/mikevasi/risk-aversion-in-the-stock-market, line 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### implementing a KNN imputation\n",
    "imputer = KNNImputer(n_neighbors=20, weights='distance', metric='nan_euclidean', copy=True)\n",
    "\n",
    "#df14.drop(['Sector'], axis = 1, inplace = True)\n",
    "\n",
    "df14_imputed = imputer.fit_transform(df14)\n",
    "df14_imputed = pd.DataFrame(df14_imputed)\n",
    "df14_imputed.columns = list(df14)\n",
    "df14_imputed.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Sector'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2894\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2895\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Sector'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-119-25b767300533>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf14\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Sector'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2900\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2902\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2903\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2904\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2895\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2899\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Sector'"
     ]
    }
   ],
   "source": [
    "df14['Sector']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### inspection of 0-values\n",
    "\n",
    "df14_zero_vals = df14.isin([0]).sum()\n",
    "#df14_zero_vals\n",
    "\n",
    "df15_zero_vals = df15.isin([0]).sum()\n",
    "#df15_zero_vals\n",
    "\n",
    "df16_zero_vals = df16.isin([0]).sum()\n",
    "#df16_zero_vals\n",
    "\n",
    "df17_zero_vals = df17.isin([0]).sum()\n",
    "#df17_zero_vals\n",
    "\n",
    "df18_zero_vals = df18.isin([0]).sum()\n",
    "#df18_zero_vals\n",
    "\n",
    "\n",
    "#seq = np.arange(df14.shape[1])\n",
    "#y = df14_zero_vals.values.tolist()\n",
    "#plt.figure(figsize=(50,10))\n",
    "#plt.subplot(2,1,2)\n",
    "#plt.bar(seq, y)\n",
    "#plt.ylabel('number of 0-values', fontsize = 50)\n",
    "#plt.xticks(seq, df14_zero_vals.index.values, rotation = 'vertical')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-9b9c62ce6ecd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    888\u001b[0m         \"\"\"\n\u001b[0;32m    889\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 890\u001b[1;33m         super().fit(\n\u001b[0m\u001b[0;32m    891\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    892\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    154\u001b[0m             \u001b[0mcheck_X_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m             \u001b[0mcheck_y_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m             X, y = self._validate_data(X, y,\n\u001b[0m\u001b[0;32m    157\u001b[0m                                        validate_separately=(check_X_params,\n\u001b[0;32m    158\u001b[0m                                                             check_y_params))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    427\u001b[0m                 \u001b[1;31m# :(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m                 \u001b[0mcheck_X_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_y_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_separately\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m                 \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_X_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m             _assert_all_finite(array,\n\u001b[0m\u001b[0;32m    645\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m     94\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m     95\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m     97\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m                     (type_err,\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "##### naive classification tree in order to see whether one of the variables ommitted is able to explain the dependent variable\n",
    "X = df14.drop(['Class', 'Sector'], axis=1)\n",
    "Y = df14['Class']\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=100)\n",
    "tree.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputing\n",
    "\n",
    "possible ways of imputing:\n",
    "* dropna() -> not very elaborate, dropping all NAs would result in a major data waste\n",
    "* fillna() -> very simplistic method, probably not appropriate\n",
    "* imputing with mean values -> [...] [T]he correlation structure of a dataset may not be captured if the decision is to plug missing values with zeros or with mean value over the samples. (Imputation of Missing Values in Economic and Financial Time Series Data Using Five Principal Component Analysis (PCA) Approaches, 2019, s. 52)\n",
    "* imputing with median values\n",
    "* imputing with most frequent value\n",
    "* imputing with mean/median/most frequent value of each of the sectors (assuming macro-trends and macro-factors within each sector)\n",
    "* KNN imputation\n",
    "* iterative imputer (scikit-learn)\n",
    "\n",
    "\n",
    "possible papers:\n",
    "* A review on missing value estimation using imputation algorithm, Journal of Physics ConferenceSeries\n",
    "* Gautrain, C., & Ravi, V. (2015). Data imputation via evolutionary computation,clustering and a neural network. Neurocomputing, 156:134-142\n",
    "* Ping, X. O., Lai F., Tseng Y.J, Liang J. D., Huang G. T., Yang, P.M. (2014).Evaluation of imputation methods for missing data and their eﬀect on thereliability of predictive models. International Conference on Bioinformatics,Biocomputational Systems and Biotechnologies, 6, 8-14.\n",
    "* Schmitt, P; Mandel, J; & Guedj, M. (2015). A comparison of six methods formissing data imputation. Journal of Biometrics & Biostatistics, 6(224), 1-6.\n",
    "* Imputation of Missing Values in Economic and Financial Time Series Data Using Five Principal Component Analysis (PCA) Approaches, August 2019, Central Bank of Nigeria Journal of Applied Statistics, DOI: 10.33429/Cjas.10119.3/6\n",
    "* IMPUTATION OF MISSING VALUES IN THE FUNDAMENTAL DATA: UNLEASHING MICE FRAMEWORK "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topics to consider\n",
    "* imputing\n",
    "    * (e.g. KNN, https://www.kaggle.com/priyankasachdeva20/catboost-model-to-classify-buy-or-sell-stocks/comments line 11)\n",
    "    * https://scikit-learn.org/stable/modules/impute.html\n",
    "    * perhaps different methods for different variables\n",
    "* 0s in df\n",
    "* outliers\n",
    "    * Z score\n",
    "    * IQR\n",
    "\n",
    "\n",
    "\n",
    "* selection of relevant ratios/fundamental data\n",
    "    * remove variables which are heavily correlated to each other (see line 7 in https://www.kaggle.com/mikevasi/risk-aversion-in-the-stock-market)\n",
    "* feature engineering \n",
    "    * https://www.nber.org/system/files/working_papers/w25398/w25398.pdf (Dacheng, Empirical Asset Pricing via ML)\n",
    "    * momentum?\n",
    "    * categorical variable for market cap\n",
    "* class imbalance\n",
    "    * use the stratify option available within sklearn.model_selection.train_test_split\n",
    "* analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
